#!/usr/bin/env python3
"""
ï¿½ DEDUPLICADOR INTELIGENTE EN TIEMPO REAL - ICT ENGINE v6.0 ENTERPRISE
========================================================================
Sistema avanzado de deduplicaciÃ³n que combina:
- DeduplicaciÃ³n tradicional por hash
- AnÃ¡lisis de patrones inteligente
- DetecciÃ³n de logs crÃ­ticos
- SupresiÃ³n automÃ¡tica de logs verbosos
- EstadÃ­sticas de optimizaciÃ³n en tiempo real

Autor: ICT Engine v6.0 Team
Fecha: 2025-09-10 (Optimizado)
"""

from protocols.unified_logging import get_unified_logger
import time
import hashlib
import re
from collections import deque, defaultdict
from datetime import datetime, timedelta
from typing import Dict, Optional, Set, List
import json
from pathlib import Path

class RealtimeLogDeduplicator:
    """ğŸ§  Sistema inteligente de deduplicaciÃ³n en tiempo real para logs"""
    
    def __init__(self, max_duplicates_per_minute=5, window_minutes=1):
        self.max_duplicates = max_duplicates_per_minute
        self.window_seconds = window_minutes * 60
        self.message_history = deque(maxlen=1000)
        self.message_counts = {}
        
        # === NUEVAS CARACTERÃSTICAS INTELIGENTES ===
        
        # Patrones crÃ­ticos que NUNCA deben suprimirse
        self.critical_patterns = [
            r'âŒ.*[Ee]rror',
            r'ğŸš¨.*[Ee]mergency',
            r'âš ï¸.*[Cc]ritical',
            r'ğŸ’°.*[Tt]rading.*[Ee]xecution',
            r'ğŸ”’.*[Ss]ecurity',
            r'ğŸš€.*[Ss]ystem.*[Ss]tart',
            r'âœ….*[Cc]onnected',
            r'âŒ.*[Dd]isconnected',
            r'ğŸ¯.*[Ss]ignal.*[Gg]enerated'
        ]
        
        # Patrones verbosos que pueden suprimirse agresivamente
        self.verbose_patterns = [
            r'â„¹ï¸.*\[AdvancedCandleDownloader.*ğŸ“Š',
            r'â„¹ï¸.*\[AdvancedCandleDownloader.*ğŸ“¡',
            r'â„¹ï¸.*\[AdvancedCandleDownloader.*ğŸ”„',
            r'â„¹ï¸.*\[AdvancedCandleDownloader.*ğŸ“¥',
            r'â„¹ï¸.*\[AdvancedCandleDownloader.*ğŸ“Š.*ICT',
            r'âœ….*enhancement.*\d+/\d+',
            r'â„¹ï¸.*Pandas thread-safe',
            r'â„¹ï¸.*MT5 conectado y funcionando',
            r'â„¹ï¸.*Storage:.*Memoria.*MANUAL',
            r'â„¹ï¸.*Timeframe.*->.*MT5 constant'
        ]
        
        # EstadÃ­sticas inteligentes
        self.stats = {
            'total_processed': 0,
            'critical_preserved': 0,
            'verbose_suppressed': 0,
            'duplicate_suppressed': 0,
            'normal_logged': 0,
            'last_reset': datetime.now()
        }
        
        # Cache de similitud para detecciÃ³n avanzada
        self.similarity_cache = {}
        self.last_cleanup = datetime.now()
        
        # Cargar configuraciÃ³n
        self._load_config()
        
    def _load_config(self):
        """Cargar configuraciÃ³n de throttling"""
        try:
            config_path = Path("01-CORE/config/log_throttle_config.json")
            if config_path.exists():
                with open(config_path) as f:
                    config = json.load(f)
                    self.max_duplicates = config.get("max_duplicates_per_minute", 5)
                    rate_limit = config.get("rate_limiting", {})
                    if rate_limit.get("enabled", True):
                        self.max_duplicates = rate_limit.get("max_identical_messages", 5)
        except:
            pass  # Usar valores por defecto
        
    def should_log(self, message: str, component: str = "UNKNOWN") -> bool:
        """
        ğŸ§  Determina inteligentemente si un mensaje debe loggearse
        
        Args:
            message: Mensaje a evaluar
            component: Componente que genera el log
            
        Returns:
            True si debe loggearse, False si debe bloquearse
        """
        self.stats['total_processed'] += 1
        now = datetime.now()
        
        # PASO 1: Verificar si es crÃ­tico (NUNCA suprimir)
        if self._is_critical_message(message):
            self.stats['critical_preserved'] += 1
            self._register_message(message, now)
            return True
        
        # PASO 2: Verificar si es verboso (suprimir agresivamente)
        if self._is_verbose_message(message):
            # Para mensajes verbosos, usar lÃ­mites mÃ¡s estrictos
            if not self._should_allow_verbose(message, now):
                self.stats['verbose_suppressed'] += 1
                return False
        
        # PASO 3: DeduplicaciÃ³n tradicional mejorada
        message_hash = self._get_smart_hash(message)
        
        # Limpiar mensajes antiguos
        self._cleanup_old_messages(now)
        
        # Contar ocurrencias recientes
        recent_count = self.message_counts.get(message_hash, 0)
        
        if recent_count >= self.max_duplicates:
            self.stats['duplicate_suppressed'] += 1
            return False  # Bloquear mensaje duplicado
        
        # PASO 4: Registrar mensaje y permitir
        self._register_message(message, now, message_hash)
        self.stats['normal_logged'] += 1
        
        return True
    
    def _is_critical_message(self, message: str) -> bool:
        """ğŸš¨ Verificar si es un mensaje crÃ­tico que nunca debe suprimirse"""
        for pattern in self.critical_patterns:
            if re.search(pattern, message, re.IGNORECASE):
                return True
        return False
    
    def _is_verbose_message(self, message: str) -> bool:
        """ğŸ”‡ Verificar si es un mensaje verboso que puede suprimirse"""
        for pattern in self.verbose_patterns:
            if re.search(pattern, message):
                return True
        return False
    
    def _should_allow_verbose(self, message: str, current_time: datetime) -> bool:
        """â° Verificar si permitir mensaje verboso (lÃ­mites mÃ¡s estrictos)"""
        # Para mensajes verbosos, permitir mÃ¡ximo 1 cada 10 segundos del mismo tipo
        message_hash = self._get_smart_hash(message)
        
        if message_hash in self.similarity_cache:
            last_time = self.similarity_cache[message_hash]
            time_diff = (current_time - last_time).total_seconds()
            if time_diff < 10:  # LÃ­mite estricto de 10 segundos para verbosos
                return False
        
        self.similarity_cache[message_hash] = current_time
        return True
    
    def _get_smart_hash(self, message: str) -> str:
        """ğŸ”‘ Obtener hash inteligente normalizando valores variables"""
        # Normalizar mensaje removiendo timestamps y valores que cambian
        normalized = re.sub(r'\d{4}-\d{2}-\d{2}.*?\d{2}:\d{2}:\d{2}', '[TIME]', message)
        normalized = re.sub(r'\d+\.\d+ms', '[MS]', normalized)
        normalized = re.sub(r'\d+\.\d+', '[NUM]', normalized)
        normalized = re.sub(r'\d{5,}', '[BIGNUM]', normalized)  # NÃºmeros grandes como velas
        normalized = re.sub(r'\d+/\d+', '[FRAC]', normalized)  # Fracciones como 3/15
        
        return hashlib.md5(normalized.encode()).hexdigest()
    
    def _register_message(self, message: str, current_time: datetime, message_hash: Optional[str] = None):
        """ğŸ“ Registrar mensaje en el historial"""
        if message_hash is None:
            message_hash = self._get_smart_hash(message)
        
        # Registrar en historial
        self.message_history.append((current_time, message_hash))
        self.message_counts[message_hash] = self.message_counts.get(message_hash, 0) + 1
    
    def _cleanup_old_messages(self, current_time):
        """ğŸ§¹ Limpiar mensajes fuera de la ventana de tiempo + cache de similitud"""
        cutoff_time = current_time - timedelta(seconds=self.window_seconds)
        
        # Limpiar deque
        while self.message_history and self.message_history[0][0] < cutoff_time:
            old_time, old_hash = self.message_history.popleft()
            if old_hash in self.message_counts:
                self.message_counts[old_hash] -= 1
                if self.message_counts[old_hash] <= 0:
                    del self.message_counts[old_hash]
        
        # Limpiar cache de similitud cada 60 segundos
        if (current_time - self.last_cleanup).total_seconds() > 60:
            similarity_cutoff = current_time - timedelta(seconds=30)
            self.similarity_cache = {
                h: t for h, t in self.similarity_cache.items() 
                if t > similarity_cutoff
            }
            self.last_cleanup = current_time
    
    def get_stats(self) -> Dict:
        """ğŸ“Š Obtener estadÃ­sticas completas del deduplicador inteligente"""
        total_processed = self.stats['total_processed']
        total_suppressed = (self.stats['verbose_suppressed'] + 
                          self.stats['duplicate_suppressed'])
        
        return {
            # EstadÃ­sticas bÃ¡sicas
            'active_messages': len(self.message_counts),
            'total_tracked': len(self.message_history),
            'similarity_cache_size': len(self.similarity_cache),
            'window_seconds': self.window_seconds,
            'max_duplicates': self.max_duplicates,
            
            # EstadÃ­sticas inteligentes
            'total_processed': total_processed,
            'critical_preserved': self.stats['critical_preserved'],
            'verbose_suppressed': self.stats['verbose_suppressed'], 
            'duplicate_suppressed': self.stats['duplicate_suppressed'],
            'normal_logged': self.stats['normal_logged'],
            'total_suppressed': total_suppressed,
            'suppression_rate': f"{(total_suppressed / max(1, total_processed) * 100):.1f}%",
            'critical_rate': f"{(self.stats['critical_preserved'] / max(1, total_processed) * 100):.1f}%",
            'last_reset': self.stats['last_reset'].isoformat()
        }
    
    def reset(self):
        """ğŸ”„ Resetear el deduplicador y estadÃ­sticas"""
        self.message_history.clear()
        self.message_counts.clear()
        self.similarity_cache.clear()
        
        # Resetear estadÃ­sticas
        self.stats = {
            'total_processed': 0,
            'critical_preserved': 0,
            'verbose_suppressed': 0,
            'duplicate_suppressed': 0,
            'normal_logged': 0,
            'last_reset': datetime.now()
        }

# Instancia global
DEDUPLICATOR = RealtimeLogDeduplicator()

def should_log_message(message: str, component: str = "UNKNOWN") -> bool:
    """ğŸ§  FunciÃ³n inteligente para verificar si un mensaje debe loggearse"""
    return DEDUPLICATOR.should_log(message, component)

def get_deduplicator_stats() -> Dict:
    """ğŸ“Š FunciÃ³n de conveniencia para obtener estadÃ­sticas completas"""
    return DEDUPLICATOR.get_stats()

def reset_deduplicator():
    """ğŸ”„ FunciÃ³n de conveniencia para resetear el deduplicador"""
    DEDUPLICATOR.reset()

def show_deduplicator_summary():
    """ğŸ“Š Mostrar resumen completo del deduplicador"""
    stats = get_deduplicator_stats()
    
    print("\nğŸ§  RESUMEN DEDUPLICADOR INTELIGENTE")
    print("=" * 50)
    print(f"ğŸ“ˆ Total procesados: {stats['total_processed']}")
    print(f"ğŸ”‡ Total suprimidos: {stats['total_suppressed']}")
    print(f"   â€¢ Verbosos: {stats['verbose_suppressed']}")
    print(f"   â€¢ Duplicados: {stats['duplicate_suppressed']}")
    print(f"ğŸš¨ CrÃ­ticos preservados: {stats['critical_preserved']}")
    print(f"âœ… Normales loggeados: {stats['normal_logged']}")
    print(f"ğŸ“Š Tasa supresiÃ³n: {stats['suppression_rate']}")
    print(f"ğŸ¯ Tasa crÃ­ticos: {stats['critical_rate']}")
    print(f"ğŸ’¾ Cache activo: {stats['similarity_cache_size']} patrones")
    print("=" * 50)
